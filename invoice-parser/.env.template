# API Keys for LLM providers
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# LLM Model Configuration
LLM_PROVIDER=openai  # options: openai, anthropic
OPENAI_MODEL=gpt-4.1-mini  # options: gpt-4o, gpt-4.1-mini
ANTHROPIC_MODEL=claude-3-haiku-20240307

# OpenAI GPT-4.1 mini pricing
GPT41MINI_PROMPT_PRICE=40  # $0.40 per million tokens for input
GPT41MINI_COMPLETION_PRICE=160  # $1.60 per million tokens for output
# Claude Haiku pricing (in cents per million tokens)
ANTHROPIC_PROMPT_PRICE=80  # $0.80 per million tokens for input
ANTHROPIC_COMPLETION_PRICE=400  # $4.00 per million tokens for output

# Flask Configuration
FLASK_DEBUG=1  # Use this instead of FLASK_ENV
FLASK_APP=app.py
PORT=5002
NUMBER_OF_WORKER_THREADS=10 # Maximum number of concurrent requests to the LLM

# File Storage
UPLOAD_FOLDER=uploads
RESULTS_FOLDER=results 